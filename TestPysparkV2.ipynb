{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKCCHdWIv8kS",
        "outputId": "6b4ad61d-890e-4a14-a65f-661409ab2ffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark==4.0.2 in /usr/local/lib/python3.12/dist-packages (4.0.2)\n",
            "Requirement already satisfied: delta-spark==4.1.0 in /usr/local/lib/python3.12/dist-packages (4.1.0)\n",
            "Requirement already satisfied: py4j<0.10.9.10,>=0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark==4.0.2) (0.10.9.9)\n",
            "Requirement already satisfied: importlib-metadata>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from delta-spark==4.1.0) (8.7.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=1.0.0->delta-spark==4.1.0) (3.23.0)\n",
            "pyspark and delta-spark installed successfully.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install pyspark==4.0.2 delta-spark==4.1.0\n",
        "\n",
        "print(\"pyspark and delta-spark installed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from delta import configure_spark_with_delta_pip\n",
        "\n",
        "# Configure SparkSession for Delta Lake\n",
        "# Use configure_spark_with_delta_pip to add Delta Lake support and explicitly add Delta configs\n",
        "spark = configure_spark_with_delta_pip(SparkSession.builder.appName(\"DeltaLakeQuickstart\")) \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(f\"SparkSession with Delta Lake support initialized successfully. Spark version: {spark.version}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2e9G-59wAfW",
        "outputId": "e9bc9f42-83ca-479f-f26a-b4ed237833aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SparkSession with Delta Lake support initialized successfully. Spark version: 4.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "# 2. Define a schema for the DataFrame\n",
        "schema = StructType([\n",
        "    StructField(\"id\", IntegerType(), True),\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"age\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "# 3. Create a list of sample data\n",
        "data = [\n",
        "    (1, \"Alice\", 30),\n",
        "    (2, \"Bob\", 24),\n",
        "    (3, \"Charlie\", 35),\n",
        "    (4, \"David\", 29)\n",
        "]\n",
        "\n",
        "# 4. Create the PySpark DataFrame\n",
        "sample_df = spark.createDataFrame(data, schema)\n",
        "\n",
        "# 5. Display the first few rows and print the schema\n",
        "sample_df.show()\n",
        "sample_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBJfNwVKwMmv",
        "outputId": "5bfc3f14-c5f2-4b38-bbc6-dcd51d6c7db4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+---+\n",
            "| id|   name|age|\n",
            "+---+-------+---+\n",
            "|  1|  Alice| 30|\n",
            "|  2|    Bob| 24|\n",
            "|  3|Charlie| 35|\n",
            "|  4|  David| 29|\n",
            "+---+-------+---+\n",
            "\n",
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "delta_table_path = \"/tmp/delta/sample_delta_table\"\n",
        "\n",
        "# Write the DataFrame as a Delta Table\n",
        "sample_df.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)\n",
        "\n",
        "print(f\"DataFrame successfully saved as Delta Table at: {delta_table_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhLGQESbwZ4o",
        "outputId": "a981c997-6a52-4a2d-9ad1-d99a8b027559"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame successfully saved as Delta Table at: /tmp/delta/sample_delta_table\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "read_df = spark.read.format(\"delta\").load(delta_table_path)\n",
        "\n",
        "print(\"Data read from Delta Table:\")\n",
        "read_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua56wEXfwoYX",
        "outputId": "5373c5f7-e99b-4c75-b215-308bd3c85ef9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data read from Delta Table:\n",
            "+---+-------+---+\n",
            "| id|   name|age|\n",
            "+---+-------+---+\n",
            "|  3|Charlie| 35|\n",
            "|  4|  David| 29|\n",
            "|  1|  Alice| 30|\n",
            "|  2|    Bob| 24|\n",
            "+---+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5R5C9kHHwr8K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}